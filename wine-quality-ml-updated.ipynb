{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine Quality Analysis - Modern ML Approach\n",
    "\n",
    "This notebook presents an updated analysis of Portuguese \"Vinho Verde\" wine quality using modern machine learning techniques.\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "**Goal**: Predict wine quality scores based on physicochemical properties\n",
    "\n",
    "**Dataset**: UCI Machine Learning Repository - Wine Quality Data\n",
    "- Red wine: 1,599 samples\n",
    "- White wine: 4,898 samples\n",
    "- Total: 6,497 wines\n",
    "\n",
    "**Features**: 11 physicochemical properties (acidity, sugar, alcohol, etc.)\n",
    "\n",
    "**Target**: Quality score (0-10, rated by wine experts)\n",
    "\n",
    "## What's New in This Analysis?\n",
    "\n",
    "1. **Advanced ML Models**: XGBoost, LightGBM, CatBoost (gradient boosting)\n",
    "2. **Model Interpretability**: SHAP values to understand predictions\n",
    "3. **Multiple Approaches**: Classification vs Regression comparison\n",
    "4. **Clustering Analysis**: Discover natural wine groupings\n",
    "5. **Interactive Visualizations**: Plotly for rich, explorable charts\n",
    "6. **Proper Validation**: Cross-validation and comprehensive metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading\n",
    "\n",
    "First, we'll import necessary libraries and load our wine data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data science libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning - Preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Traditional ML Models\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Advanced Gradient Boosting Models\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "\n",
    "# Model Interpretability\n",
    "import shap\n",
    "\n",
    "# Clustering and Dimensionality Reduction\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP\n",
    "\n",
    "# For model export\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(\"‚úÖ All libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Wine Datasets\n",
    "\n",
    "We'll load both red and white wine datasets, then combine them for analysis. We'll add a 'type' column to distinguish between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets (semicolon-separated)\n",
    "red_wine = pd.read_csv('winequality-red.csv', sep=';')\n",
    "white_wine = pd.read_csv('winequality-white.csv', sep=';')\n",
    "\n",
    "# Add wine type column (0=red, 1=white)\n",
    "red_wine['type'] = 0\n",
    "white_wine['type'] = 1\n",
    "\n",
    "# Combine datasets\n",
    "wine_data = pd.concat([red_wine, white_wine], axis=0, ignore_index=True)\n",
    "\n",
    "print(f\"Red wines: {len(red_wine):,}\")\n",
    "print(f\"White wines: {len(white_wine):,}\")\n",
    "print(f\"Total wines: {len(wine_data):,}\")\n",
    "print(f\"\\nFeatures: {list(wine_data.columns)}\")\n",
    "print(f\"\\nDataset shape: {wine_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Let's understand our data through visualization and statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"=== Dataset Info ===\")\n",
    "print(wine_data.info())\n",
    "print(\"\\n=== Missing Values ===\")\n",
    "print(wine_data.isnull().sum())\n",
    "print(\"\\n=== Quality Distribution ===\")\n",
    "print(wine_data['quality'].value_counts().sort_index())\n",
    "print(\"\\n=== Statistical Summary ===\")\n",
    "wine_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Distribution Visualization\n",
    "\n",
    "Most wines are rated between 5-7, with few exceptional (9-10) or poor (3-4) wines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive quality distribution plot\n",
    "fig = px.histogram(wine_data, x='quality', color='type', \n",
    "                   labels={'type': 'Wine Type', 'quality': 'Quality Score'},\n",
    "                   title='Wine Quality Distribution by Type',\n",
    "                   color_discrete_map={0: 'darkred', 1: 'gold'},\n",
    "                   barmode='group')\n",
    "fig.update_layout(height=400)\n",
    "fig.show()\n",
    "\n",
    "# Save for web\n",
    "fig.write_html('docs/quality_distribution.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Correlations\n",
    "\n",
    "Understanding which features are most correlated with wine quality helps us build better models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with quality\n",
    "correlations = wine_data.corr()['quality'].sort_values(ascending=False)\n",
    "print(\"=== Correlation with Quality ===\")\n",
    "print(correlations)\n",
    "\n",
    "# Interactive correlation heatmap\n",
    "corr_matrix = wine_data.corr()\n",
    "fig = px.imshow(corr_matrix, \n",
    "                text_auto='.2f',\n",
    "                aspect='auto',\n",
    "                title='Feature Correlation Heatmap',\n",
    "                color_continuous_scale='RdBu_r')\n",
    "fig.update_layout(height=700)\n",
    "fig.show()\n",
    "\n",
    "# Save for web\n",
    "fig.write_html('docs/correlation_heatmap.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Relationships\n",
    "\n",
    "Let's visualize the most important feature relationships with quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top features by correlation\n",
    "top_features = correlations.abs().sort_values(ascending=False)[1:6].index.tolist()\n",
    "\n",
    "# Create subplots for top features\n",
    "fig = make_subplots(rows=2, cols=3, \n",
    "                    subplot_titles=[f'{feat.title()} vs Quality' for feat in top_features] + ['Wine Type Distribution'])\n",
    "\n",
    "for idx, feature in enumerate(top_features, 1):\n",
    "    row = (idx - 1) // 3 + 1\n",
    "    col = (idx - 1) % 3 + 1\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Box(x=wine_data['quality'], y=wine_data[feature], name=feature),\n",
    "        row=row, col=col\n",
    "    )\n",
    "\n",
    "# Add wine type distribution\n",
    "type_counts = wine_data['type'].value_counts()\n",
    "fig.add_trace(\n",
    "    go.Bar(x=['Red', 'White'], y=[type_counts[0], type_counts[1]], \n",
    "           marker_color=['darkred', 'gold']),\n",
    "    row=2, col=3\n",
    ")\n",
    "\n",
    "fig.update_layout(height=800, showlegend=False, title_text='Key Feature Relationships')\n",
    "fig.show()\n",
    "\n",
    "# Save for web\n",
    "fig.write_html('docs/feature_relationships.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "We'll clean the data and prepare it for machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection and Removal\n",
    "\n",
    "Using the Z-score method, we'll identify and remove extreme outliers (|z| > 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Z-scores for numerical features\n",
    "from scipy import stats\n",
    "\n",
    "numerical_features = wine_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numerical_features.remove('quality')  # Don't remove outliers from target\n",
    "numerical_features.remove('type')  # Don't remove outliers from categorical\n",
    "\n",
    "# Calculate Z-scores\n",
    "z_scores = np.abs(stats.zscore(wine_data[numerical_features]))\n",
    "\n",
    "# Find outliers (|z| > 3)\n",
    "outlier_rows = (z_scores > 3).any(axis=1)\n",
    "\n",
    "print(f\"Outliers found: {outlier_rows.sum()} ({100*outlier_rows.sum()/len(wine_data):.2f}%)\")\n",
    "\n",
    "# Create cleaned dataset\n",
    "wine_cleaned = wine_data[~outlier_rows].copy()\n",
    "\n",
    "# Also remove wines with quality 3 and 9 (too few samples)\n",
    "wine_cleaned = wine_cleaned[~wine_cleaned['quality'].isin([3, 9])]\n",
    "\n",
    "print(f\"\\nDataset size after cleaning: {len(wine_cleaned):,} wines\")\n",
    "print(f\"Removed: {len(wine_data) - len(wine_cleaned):,} samples\")\n",
    "print(f\"\\nQuality distribution after cleaning:\")\n",
    "print(wine_cleaned['quality'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Let's create some derived features that might improve our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features\n",
    "wine_cleaned['total_acidity'] = wine_cleaned['fixed acidity'] + wine_cleaned['volatile acidity']\n",
    "wine_cleaned['free_sulfur_ratio'] = wine_cleaned['free sulfur dioxide'] / wine_cleaned['total sulfur dioxide']\n",
    "wine_cleaned['alcohol_to_density'] = wine_cleaned['alcohol'] / wine_cleaned['density']\n",
    "\n",
    "# Create quality categories for classification\n",
    "wine_cleaned['quality_category'] = pd.cut(wine_cleaned['quality'], \n",
    "                                           bins=[0, 5, 6, 10],\n",
    "                                           labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "# Binary classification: Good (7-8) vs Not Good (4-6)\n",
    "wine_cleaned['is_good_wine'] = (wine_cleaned['quality'] >= 7).astype(int)\n",
    "\n",
    "print(\"New features created:\")\n",
    "print(\"- total_acidity\")\n",
    "print(\"- free_sulfur_ratio\")\n",
    "print(\"- alcohol_to_density\")\n",
    "print(\"- quality_category (Low/Medium/High)\")\n",
    "print(\"- is_good_wine (binary: 0/1)\")\n",
    "print(f\"\\nBinary classification distribution:\")\n",
    "print(wine_cleaned['is_good_wine'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split\n",
    "\n",
    "We'll split our data into training (70%) and testing (30%) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "feature_cols = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "                'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "                'pH', 'sulphates', 'alcohol', 'type', 'total_acidity', \n",
    "                'free_sulfur_ratio', 'alcohol_to_density']\n",
    "\n",
    "X = wine_cleaned[feature_cols]\n",
    "y_multiclass = wine_cleaned['quality']  # For multi-class classification (4-8)\n",
    "y_binary = wine_cleaned['is_good_wine']  # For binary classification\n",
    "y_regression = wine_cleaned['quality']  # For regression\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train_mc, y_test_mc = train_test_split(\n",
    "    X, y_multiclass, test_size=0.3, random_state=RANDOM_STATE, stratify=y_multiclass\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train_bin, y_test_bin = train_test_split(\n",
    "    X, y_binary, test_size=0.3, random_state=RANDOM_STATE, stratify=y_binary\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train_reg, y_test_reg = train_test_split(\n",
    "    X, y_regression, test_size=0.3, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Standardize features (important for some models)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set size: {len(X_train):,}\")\n",
    "print(f\"Test set size: {len(X_test):,}\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Baseline Models\n",
    "\n",
    "Let's quickly train the original models to establish a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store results\n",
    "results = {\n",
    "    'model': [],\n",
    "    'accuracy': [],\n",
    "    'cv_score_mean': [],\n",
    "    'cv_score_std': []\n",
    "}\n",
    "\n",
    "# Random Forest (original best model)\n",
    "print(\"Training Random Forest (baseline)...\")\n",
    "rf_baseline = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "rf_baseline.fit(X_train, y_train_mc)\n",
    "rf_pred = rf_baseline.predict(X_test)\n",
    "rf_acc = accuracy_score(y_test_mc, rf_pred)\n",
    "\n",
    "# Cross-validation\n",
    "rf_cv_scores = cross_val_score(rf_baseline, X_train, y_train_mc, cv=5, n_jobs=-1)\n",
    "\n",
    "results['model'].append('Random Forest (Baseline)')\n",
    "results['accuracy'].append(rf_acc)\n",
    "results['cv_score_mean'].append(rf_cv_scores.mean())\n",
    "results['cv_score_std'].append(rf_cv_scores.std())\n",
    "\n",
    "print(f\"‚úÖ Random Forest Accuracy: {rf_acc:.4f}\")\n",
    "print(f\"   Cross-validation: {rf_cv_scores.mean():.4f} (+/- {rf_cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Models: Gradient Boosting\n",
    "\n",
    "Now let's train modern gradient boosting models that typically outperform Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "\n",
    "XGBoost is a powerful gradient boosting library known for winning ML competitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training XGBoost...\")\n",
    "\n",
    "# XGBoost expects labels starting from 0\n",
    "y_train_xgb = y_train_mc - y_train_mc.min()\n",
    "y_test_xgb = y_test_mc - y_test_mc.min()\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='mlogloss'\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train_xgb)\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "xgb_acc = accuracy_score(y_test_xgb, xgb_pred)\n",
    "\n",
    "# Cross-validation\n",
    "xgb_cv_scores = cross_val_score(xgb_model, X_train, y_train_xgb, cv=5, n_jobs=-1)\n",
    "\n",
    "results['model'].append('XGBoost')\n",
    "results['accuracy'].append(xgb_acc)\n",
    "results['cv_score_mean'].append(xgb_cv_scores.mean())\n",
    "results['cv_score_std'].append(xgb_cv_scores.std())\n",
    "\n",
    "print(f\"‚úÖ XGBoost Accuracy: {xgb_acc:.4f}\")\n",
    "print(f\"   Cross-validation: {xgb_cv_scores.mean():.4f} (+/- {xgb_cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM\n",
    "\n",
    "LightGBM is faster than XGBoost and often achieves similar or better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training LightGBM...\")\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "lgb_model.fit(X_train, y_train_mc)\n",
    "lgb_pred = lgb_model.predict(X_test)\n",
    "lgb_acc = accuracy_score(y_test_mc, lgb_pred)\n",
    "\n",
    "# Cross-validation\n",
    "lgb_cv_scores = cross_val_score(lgb_model, X_train, y_train_mc, cv=5, n_jobs=-1)\n",
    "\n",
    "results['model'].append('LightGBM')\n",
    "results['accuracy'].append(lgb_acc)\n",
    "results['cv_score_mean'].append(lgb_cv_scores.mean())\n",
    "results['cv_score_std'].append(lgb_cv_scores.std())\n",
    "\n",
    "print(f\"‚úÖ LightGBM Accuracy: {lgb_acc:.4f}\")\n",
    "print(f\"   Cross-validation: {lgb_cv_scores.mean():.4f} (+/- {lgb_cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost\n",
    "\n",
    "CatBoost excels at handling categorical features and requires minimal hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training CatBoost...\")\n",
    "\n",
    "cat_model = CatBoostClassifier(\n",
    "    iterations=200,\n",
    "    depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=RANDOM_STATE,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "cat_model.fit(X_train, y_train_mc)\n",
    "cat_pred = cat_model.predict(X_test)\n",
    "cat_acc = accuracy_score(y_test_mc, cat_pred)\n",
    "\n",
    "# Cross-validation\n",
    "cat_cv_scores = cross_val_score(cat_model, X_train, y_train_mc, cv=5, n_jobs=-1)\n",
    "\n",
    "results['model'].append('CatBoost')\n",
    "results['accuracy'].append(cat_acc)\n",
    "results['cv_score_mean'].append(cat_cv_scores.mean())\n",
    "results['cv_score_std'].append(cat_cv_scores.std())\n",
    "\n",
    "print(f\"‚úÖ CatBoost Accuracy: {cat_acc:.4f}\")\n",
    "print(f\"   Cross-validation: {cat_cv_scores.mean():.4f} (+/- {cat_cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison\n",
    "\n",
    "Let's compare all models to see which performs best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('accuracy', ascending=False)\n",
    "\n",
    "print(\"=== Model Performance Comparison ===\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Visualize comparison\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    name='Test Accuracy',\n",
    "    x=results_df['model'],\n",
    "    y=results_df['accuracy'],\n",
    "    text=[f\"{x:.3f}\" for x in results_df['accuracy']],\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    name='CV Mean',\n",
    "    x=results_df['model'],\n",
    "    y=results_df['cv_score_mean'],\n",
    "    text=[f\"{x:.3f}\" for x in results_df['cv_score_mean']],\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Model Performance Comparison',\n",
    "    xaxis_title='Model',\n",
    "    yaxis_title='Accuracy',\n",
    "    barmode='group',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig.write_html('docs/model_comparison.html')\n",
    "\n",
    "# Select best model\n",
    "best_model_name = results_df.iloc[0]['model']\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Interpretability with SHAP\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) helps us understand which features drive our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Computing SHAP values for model interpretability...\")\n",
    "\n",
    "# Use LightGBM for SHAP (fast and accurate)\n",
    "explainer = shap.TreeExplainer(lgb_model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "print(\"‚úÖ SHAP values computed\")\n",
    "\n",
    "# Summary plot - shows feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\", show=False)\n",
    "plt.title('Feature Importance (SHAP Values)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('docs/shap_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Detailed summary plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_values, X_test, show=False)\n",
    "plt.title('SHAP Summary Plot - Feature Impact on Predictions')\n",
    "plt.tight_layout()\n",
    "plt.savefig('docs/shap_summary.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP Waterfall Plot\n",
    "\n",
    "Let's examine a single prediction to see how features contribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a sample prediction\n",
    "sample_idx = 0\n",
    "sample_wine = X_test.iloc[sample_idx]\n",
    "sample_quality = y_test_mc.iloc[sample_idx]\n",
    "predicted_quality = lgb_pred[sample_idx]\n",
    "\n",
    "print(f\"Sample Wine #{sample_idx}\")\n",
    "print(f\"Actual Quality: {sample_quality}\")\n",
    "print(f\"Predicted Quality: {predicted_quality}\")\n",
    "print(f\"\\nFeatures:\")\n",
    "print(sample_wine)\n",
    "\n",
    "# Create SHAP explanation for this sample\n",
    "shap.plots.waterfall(explainer(X_test.iloc[[sample_idx]])[0], show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Regression Approach\n",
    "\n",
    "Since quality is an ordinal variable (4 < 5 < 6...), let's try regression instead of classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training regression models...\")\n",
    "\n",
    "# LightGBM Regressor\n",
    "lgb_reg = lgb.LGBMRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "lgb_reg.fit(X_train, y_train_reg)\n",
    "lgb_reg_pred = lgb_reg.predict(X_test)\n",
    "\n",
    "# Convert continuous predictions to discrete quality scores\n",
    "lgb_reg_pred_rounded = np.round(lgb_reg_pred).astype(int)\n",
    "lgb_reg_pred_rounded = np.clip(lgb_reg_pred_rounded, 4, 8)  # Ensure valid range\n",
    "\n",
    "# Metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_test_reg, lgb_reg_pred))\n",
    "mae = mean_absolute_error(y_test_reg, lgb_reg_pred)\n",
    "r2 = r2_score(y_test_reg, lgb_reg_pred)\n",
    "accuracy_reg = accuracy_score(y_test_reg, lgb_reg_pred_rounded)\n",
    "\n",
    "print(f\"\\n=== Regression Results ===\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"R¬≤ Score: {r2:.4f}\")\n",
    "print(f\"Accuracy (rounded): {accuracy_reg:.4f}\")\n",
    "\n",
    "# Visualize predictions vs actual\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=y_test_reg,\n",
    "    y=lgb_reg_pred,\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, opacity=0.5),\n",
    "    name='Predictions'\n",
    "))\n",
    "\n",
    "# Perfect prediction line\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[4, 8],\n",
    "    y=[4, 8],\n",
    "    mode='lines',\n",
    "    line=dict(color='red', dash='dash'),\n",
    "    name='Perfect Prediction'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Regression: Predicted vs Actual Quality',\n",
    "    xaxis_title='Actual Quality',\n",
    "    yaxis_title='Predicted Quality',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig.write_html('docs/regression_predictions.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Binary Classification: Good vs Not Good\n",
    "\n",
    "A simpler approach: classify wines as \"Good\" (7-8) or \"Not Good\" (4-6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training binary classification model...\")\n",
    "\n",
    "lgb_binary = lgb.LGBMClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "lgb_binary.fit(X_train, y_train_bin)\n",
    "lgb_binary_pred = lgb_binary.predict(X_test)\n",
    "lgb_binary_proba = lgb_binary.predict_proba(X_test)[:, 1]\n",
    "\n",
    "binary_acc = accuracy_score(y_test_bin, lgb_binary_pred)\n",
    "\n",
    "print(f\"\\n=== Binary Classification Results ===\")\n",
    "print(f\"Accuracy: {binary_acc:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_bin, lgb_binary_pred, \n",
    "                          target_names=['Not Good (4-6)', 'Good (7-8)']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test_bin, lgb_binary_pred)\n",
    "fig = px.imshow(cm, \n",
    "                text_auto=True,\n",
    "                labels=dict(x='Predicted', y='Actual'),\n",
    "                x=['Not Good', 'Good'],\n",
    "                y=['Not Good', 'Good'],\n",
    "                title='Binary Classification Confusion Matrix',\n",
    "                color_continuous_scale='Blues')\n",
    "fig.show()\n",
    "fig.write_html('docs/binary_confusion_matrix.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Clustering Analysis\n",
    "\n",
    "Let's discover natural groupings in the wine data using unsupervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering\n",
    "\n",
    "We'll find the optimal number of clusters using the elbow method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data for clustering\n",
    "X_clustering = wine_cleaned[feature_cols]\n",
    "X_clustering_scaled = StandardScaler().fit_transform(X_clustering)\n",
    "\n",
    "# Elbow method to find optimal k\n",
    "inertias = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=10)\n",
    "    kmeans.fit(X_clustering_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "# Plot elbow curve\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=list(K_range), y=inertias, mode='lines+markers'))\n",
    "fig.update_layout(\n",
    "    title='Elbow Method for Optimal K',\n",
    "    xaxis_title='Number of Clusters',\n",
    "    yaxis_title='Inertia',\n",
    "    height=400\n",
    ")\n",
    "fig.show()\n",
    "fig.write_html('docs/elbow_curve.html')\n",
    "\n",
    "# Use k=4 based on elbow\n",
    "optimal_k = 4\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=RANDOM_STATE, n_init=10)\n",
    "wine_cleaned['cluster'] = kmeans.fit_predict(X_clustering_scaled)\n",
    "\n",
    "print(f\"\\n=== K-Means Clustering (k={optimal_k}) ===\")\n",
    "print(f\"Cluster distribution:\")\n",
    "print(wine_cleaned['cluster'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Characteristics\n",
    "\n",
    "Let's understand what distinguishes each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cluster characteristics\n",
    "cluster_stats = wine_cleaned.groupby('cluster')[['alcohol', 'volatile acidity', \n",
    "                                                   'residual sugar', 'quality']].mean()\n",
    "\n",
    "print(\"\\n=== Average Characteristics by Cluster ===\")\n",
    "print(cluster_stats)\n",
    "\n",
    "# Visualize cluster characteristics\n",
    "fig = go.Figure()\n",
    "\n",
    "for col in ['alcohol', 'volatile acidity', 'residual sugar', 'quality']:\n",
    "    fig.add_trace(go.Bar(\n",
    "        name=col.title(),\n",
    "        x=[f'Cluster {i}' for i in range(optimal_k)],\n",
    "        y=cluster_stats[col]\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Cluster Characteristics',\n",
    "    xaxis_title='Cluster',\n",
    "    yaxis_title='Average Value',\n",
    "    barmode='group',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig.write_html('docs/cluster_characteristics.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction Visualization\n",
    "\n",
    "Using PCA and UMAP to visualize clusters in 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA for 2D visualization\n",
    "pca = PCA(n_components=2, random_state=RANDOM_STATE)\n",
    "X_pca = pca.fit_transform(X_clustering_scaled)\n",
    "\n",
    "wine_cleaned['pca1'] = X_pca[:, 0]\n",
    "wine_cleaned['pca2'] = X_pca[:, 1]\n",
    "\n",
    "# PCA visualization colored by cluster\n",
    "fig = px.scatter(wine_cleaned, x='pca1', y='pca2', color='cluster',\n",
    "                 title=f'Wine Clusters (PCA) - Explained Variance: {pca.explained_variance_ratio_.sum():.2%}',\n",
    "                 labels={'pca1': f'PC1 ({pca.explained_variance_ratio_[0]:.1%})',\n",
    "                        'pca2': f'PC2 ({pca.explained_variance_ratio_[1]:.1%})'},\n",
    "                 hover_data=['quality', 'alcohol', 'volatile acidity'])\n",
    "fig.update_traces(marker=dict(size=4, opacity=0.6))\n",
    "fig.update_layout(height=600)\n",
    "fig.show()\n",
    "fig.write_html('docs/pca_clusters.html')\n",
    "\n",
    "# PCA colored by quality\n",
    "fig = px.scatter(wine_cleaned, x='pca1', y='pca2', color='quality',\n",
    "                 title='Wine Quality Distribution (PCA)',\n",
    "                 labels={'pca1': f'PC1 ({pca.explained_variance_ratio_[0]:.1%})',\n",
    "                        'pca2': f'PC2 ({pca.explained_variance_ratio_[1]:.1%})'},\n",
    "                 color_continuous_scale='RdYlGn',\n",
    "                 hover_data=['alcohol', 'volatile acidity'])\n",
    "fig.update_traces(marker=dict(size=4, opacity=0.6))\n",
    "fig.update_layout(height=600)\n",
    "fig.show()\n",
    "fig.write_html('docs/pca_quality.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP Visualization\n",
    "\n",
    "UMAP often reveals better cluster separation than PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP for 2D visualization\n",
    "umap_model = UMAP(n_components=2, random_state=RANDOM_STATE, n_neighbors=15, min_dist=0.1)\n",
    "X_umap = umap_model.fit_transform(X_clustering_scaled)\n",
    "\n",
    "wine_cleaned['umap1'] = X_umap[:, 0]\n",
    "wine_cleaned['umap2'] = X_umap[:, 1]\n",
    "\n",
    "# UMAP colored by cluster\n",
    "fig = px.scatter(wine_cleaned, x='umap1', y='umap2', color='cluster',\n",
    "                 title='Wine Clusters (UMAP)',\n",
    "                 labels={'umap1': 'UMAP1', 'umap2': 'UMAP2'},\n",
    "                 hover_data=['quality', 'alcohol', 'volatile acidity'])\n",
    "fig.update_traces(marker=dict(size=4, opacity=0.6))\n",
    "fig.update_layout(height=600)\n",
    "fig.show()\n",
    "fig.write_html('docs/umap_clusters.html')\n",
    "\n",
    "# UMAP colored by quality\n",
    "fig = px.scatter(wine_cleaned, x='umap1', y='umap2', color='quality',\n",
    "                 title='Wine Quality Distribution (UMAP)',\n",
    "                 labels={'umap1': 'UMAP1', 'umap2': 'UMAP2'},\n",
    "                 color_continuous_scale='RdYlGn',\n",
    "                 hover_data=['alcohol', 'volatile acidity'])\n",
    "fig.update_traces(marker=dict(size=4, opacity=0.6))\n",
    "fig.update_layout(height=600)\n",
    "fig.show()\n",
    "fig.write_html('docs/umap_quality.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Models and Data\n",
    "\n",
    "Save our best models and data for the web dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create exports directory\n",
    "os.makedirs('docs/exports', exist_ok=True)\n",
    "\n",
    "# Save best model (LightGBM)\n",
    "joblib.dump(lgb_model, 'docs/exports/lgb_model.pkl')\n",
    "joblib.dump(scaler, 'docs/exports/scaler.pkl')\n",
    "\n",
    "print(\"‚úÖ Models saved\")\n",
    "\n",
    "# Export model performance data\n",
    "results_df.to_json('docs/exports/model_results.json', orient='records', indent=2)\n",
    "\n",
    "print(\"‚úÖ Results exported\")\n",
    "\n",
    "# Export feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': lgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "feature_importance.to_json('docs/exports/feature_importance.json', orient='records', indent=2)\n",
    "\n",
    "print(\"‚úÖ Feature importance exported\")\n",
    "\n",
    "# Export sample data for web predictor\n",
    "sample_data = wine_cleaned[feature_cols + ['quality']].sample(100, random_state=RANDOM_STATE)\n",
    "sample_data.to_json('docs/exports/sample_wines.json', orient='records', indent=2)\n",
    "\n",
    "print(\"‚úÖ Sample data exported\")\n",
    "\n",
    "# Export statistics for dashboard\n",
    "stats = {\n",
    "    'total_wines': len(wine_cleaned),\n",
    "    'red_wines': len(wine_cleaned[wine_cleaned['type'] == 0]),\n",
    "    'white_wines': len(wine_cleaned[wine_cleaned['type'] == 1]),\n",
    "    'avg_quality': float(wine_cleaned['quality'].mean()),\n",
    "    'quality_distribution': wine_cleaned['quality'].value_counts().sort_index().to_dict(),\n",
    "    'best_model': best_model_name,\n",
    "    'best_accuracy': float(results_df.iloc[0]['accuracy']),\n",
    "    'top_features': feature_importance.head(5)['feature'].tolist()\n",
    "}\n",
    "\n",
    "with open('docs/exports/stats.json', 'w') as f:\n",
    "    json.dump(stats, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Statistics exported\")\n",
    "\n",
    "# Export confusion matrix data\n",
    "cm_multiclass = confusion_matrix(y_test_mc, lgb_pred)\n",
    "np.save('docs/exports/confusion_matrix.npy', cm_multiclass)\n",
    "\n",
    "print(\"‚úÖ Confusion matrix exported\")\n",
    "\n",
    "print(\"\\nüéâ All exports complete! Ready for web dashboard.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Final Summary\n",
    "\n",
    "Let's create a comprehensive summary of our findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"WINE QUALITY ANALYSIS - FINAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìä DATASET\")\n",
    "print(f\"   Total Wines Analyzed: {len(wine_cleaned):,}\")\n",
    "print(f\"   Red Wines: {len(wine_cleaned[wine_cleaned['type']==0]):,}\")\n",
    "print(f\"   White Wines: {len(wine_cleaned[wine_cleaned['type']==1]):,}\")\n",
    "print(f\"   Features: {len(feature_cols)}\")\n",
    "\n",
    "print(f\"\\nüéØ BEST MODEL: {best_model_name}\")\n",
    "print(f\"   Test Accuracy: {results_df.iloc[0]['accuracy']:.4f} ({results_df.iloc[0]['accuracy']*100:.2f}%)\")\n",
    "print(f\"   CV Mean: {results_df.iloc[0]['cv_score_mean']:.4f}\")\n",
    "print(f\"   CV Std: {results_df.iloc[0]['cv_score_std']:.4f}\")\n",
    "\n",
    "print(f\"\\nüìà ALL MODELS\")\n",
    "for _, row in results_df.iterrows():\n",
    "    print(f\"   {row['model']:<30} {row['accuracy']:.4f}\")\n",
    "\n",
    "print(f\"\\nüîë TOP 5 IMPORTANT FEATURES\")\n",
    "for idx, row in feature_importance.head(5).iterrows():\n",
    "    print(f\"   {row['feature']:<30} {row['importance']:.4f}\")\n",
    "\n",
    "print(f\"\\nüç∑ WINE CLUSTERS\")\n",
    "print(f\"   Number of Clusters: {optimal_k}\")\n",
    "for i in range(optimal_k):\n",
    "    cluster_size = len(wine_cleaned[wine_cleaned['cluster']==i])\n",
    "    avg_quality = wine_cleaned[wine_cleaned['cluster']==i]['quality'].mean()\n",
    "    print(f\"   Cluster {i}: {cluster_size:,} wines (avg quality: {avg_quality:.2f})\")\n",
    "\n",
    "print(f\"\\n‚ú® KEY INSIGHTS\")\n",
    "print(f\"   ‚Ä¢ Gradient boosting models (XGBoost, LightGBM, CatBoost) outperform Random Forest\")\n",
    "print(f\"   ‚Ä¢ Alcohol content is the strongest predictor of wine quality\")\n",
    "print(f\"   ‚Ä¢ Volatile acidity negatively impacts quality\")\n",
    "print(f\"   ‚Ä¢ Binary classification (Good/Not Good) achieves {binary_acc:.4f} accuracy\")\n",
    "print(f\"   ‚Ä¢ Regression approach provides continuous quality estimates (RMSE: {rmse:.4f})\")\n",
    "print(f\"   ‚Ä¢ {optimal_k} natural wine clusters discovered with distinct characteristics\")\n",
    "\n",
    "print(f\"\\nüìÅ EXPORTED FILES\")\n",
    "print(f\"   ‚Ä¢ Models: lgb_model.pkl, scaler.pkl\")\n",
    "print(f\"   ‚Ä¢ Visualizations: 10+ interactive HTML charts\")\n",
    "print(f\"   ‚Ä¢ Data: model_results.json, feature_importance.json, stats.json\")\n",
    "print(f\"   ‚Ä¢ All files ready for GitHub Pages deployment\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Analysis Complete! üéâ\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
